# cs551-computer-graphics---homework-assignment-4---image-processing-solved
**TO GET THIS SOLUTION VISIT:** [CS551 Computer Graphics ‚Äì Homework Assignment 4 ‚Äì Image Processing Solved](https://www.ankitcodinghub.com/product/cs551-computer-graphics-homework-assignment-4-image-processing-solved/)


---

üì© **If you need this solution or have special requests:** **Email:** ankitcoding@gmail.com  
üì± **WhatsApp:** +1 419 877 7882  
üìÑ **Get a quote instantly using this form:** [Ask Homework Questions](https://www.ankitcodinghub.com/services/ask-homework-questions/)

*We deliver fast, professional, and affordable academic help.*

---

<h2>Description</h2>



<div class="kk-star-ratings kksr-auto kksr-align-center kksr-valign-top" data-payload="{&quot;align&quot;:&quot;center&quot;,&quot;id&quot;:&quot;97310&quot;,&quot;slug&quot;:&quot;default&quot;,&quot;valign&quot;:&quot;top&quot;,&quot;ignore&quot;:&quot;&quot;,&quot;reference&quot;:&quot;auto&quot;,&quot;class&quot;:&quot;&quot;,&quot;count&quot;:&quot;2&quot;,&quot;legendonly&quot;:&quot;&quot;,&quot;readonly&quot;:&quot;&quot;,&quot;score&quot;:&quot;5&quot;,&quot;starsonly&quot;:&quot;&quot;,&quot;best&quot;:&quot;5&quot;,&quot;gap&quot;:&quot;4&quot;,&quot;greet&quot;:&quot;Rate this product&quot;,&quot;legend&quot;:&quot;5\/5 - (2 votes)&quot;,&quot;size&quot;:&quot;24&quot;,&quot;title&quot;:&quot;CS551 Computer Graphics - Homework Assignment 4 - Image Processing Solved&quot;,&quot;width&quot;:&quot;138&quot;,&quot;_legend&quot;:&quot;{score}\/{best} - ({count} {votes})&quot;,&quot;font_factor&quot;:&quot;1.25&quot;}">

<div class="kksr-stars">

<div class="kksr-stars-inactive">
            <div class="kksr-star" data-star="1" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="2" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="3" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="4" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="5" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>

<div class="kksr-stars-active" style="width: 138px;">
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>
</div>


<div class="kksr-legend" style="font-size: 19.2px;">
            5/5 - (2 votes)    </div>
    </div>
<h2 dir="auto">O<a id="user-content-overview" class="anchor" href="https://github.com/yig/graphics101-imageprocessing#overview" aria-hidden="true"></a>verview:</h2>
<p dir="auto">In this assignment, you will be implementing image processing operations based on convolution. You will be able to scale, blur, and sharpen images, just like Photoshop. You will be able to create effects like this:

<p dir="auto"><a href="https://i0.wp.com/github.com/yig/graphics101-imageprocessing/blob/master/docs/bananas-scale-50.png?ssl=1" target="_blank" rel="noopener noreferrer"><img data-recalc-dims="1" decoding="async" data-src="https://i0.wp.com/github.com/yig/graphics101-imageprocessing/raw/master/docs/bananas-scale-50.png?w=980&amp;ssl=1" alt="Bananas scaled" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" class="lazyload"></a>&nbsp;<a href="https://i0.wp.com/github.com/yig/graphics101-imageprocessing/blob/master/docs/bananas-convolve-heart.png?ssl=1" target="_blank" rel="noopener noreferrer"><img data-recalc-dims="1" decoding="async" data-src="https://i0.wp.com/github.com/yig/graphics101-imageprocessing/raw/master/docs/bananas-convolve-heart.png?w=980&amp;ssl=1" alt="Bananas blurred with a heart" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" class="lazyload"></a>&nbsp;<a href="https://i0.wp.com/github.com/yig/graphics101-imageprocessing/blob/master/docs/bananas-edges.png?ssl=1" target="_blank" rel="noopener noreferrer"><img data-recalc-dims="1" decoding="async" data-src="https://i0.wp.com/github.com/yig/graphics101-imageprocessing/raw/master/docs/bananas-edges.png?w=980&amp;ssl=1" alt="Bananas edge detected" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" class="lazyload"></a>

<p dir="auto">Although these effects look fancy, they are all based on the same operation: convolution.

<h2 dir="auto"><a id="user-content-goals" class="anchor" href="https://github.com/yig/graphics101-imageprocessing#goals" aria-hidden="true"></a>Goals:</h2>
<ul dir="auto">
<li>Understand convolution and image processing.</li>
<li>Gain insight into high performance image processing algorithms.</li>
<li>Gain more experience with raster images.</li>
</ul>
<h2 dir="auto"><a id="user-content-background" class="anchor" href="https://github.com/yig/graphics101-imageprocessing#background" aria-hidden="true"></a>Background:</h2>
<ul dir="auto">
<li>Book (FoCG,4e): Chapter 9&nbsp;<em>Signal Processing</em>.</li>
<li>Video: ‚ÄúLecture 10: Signal Processing‚Äù and ‚ÄúAssignment 4: Image Processing‚Äù</li>
<li>Quiz: Convolution</li>
</ul>
<p dir="auto">(FoCG,4e is&nbsp;<em>Fundamentals of Computer Graphics (4th edition)</em>&nbsp;by Steve Marschner and Peter Shirley, 4th edition.)

<h2 dir="auto"><a id="user-content-getting-started--handing-in" class="anchor" href="https://github.com/yig/graphics101-imageprocessing#getting-started--handing-in" aria-hidden="true"></a>Getting Started &amp; Handing In:</h2>
<ul dir="auto">
<li>
<p dir="auto">Download or clone this code repository. Don‚Äôt fork it on GitHub, or else your code will be visible to everyone.

</li>
<li>
<p dir="auto">Follow the instructions to install a working development environment:&nbsp;<a href="https://github.com/yig/graphics101">https://github.com/yig/graphics101</a>&nbsp;. You do not need to install Qt or any other external libraries for this assignment. The framework provides all the code you need.

</li>
<li>
<p dir="auto">The code will be written in C++. You are encouraged to write helper functions. They can eliminate a lot of redundant code.

</li>
<li>
<p dir="auto">Build and run the code. The code should compile, but it will complain when running about not having enough arguments. The program is a command line program. You should see a message like:

<div class="snippet-clipboard-content notranslate position-relative overflow-auto">
<pre class="notranslate"><code>  Usage: ./imageprocessing box radius input_image.png image_out.png
  Usage: ./imageprocessing scale width_percent height_percent input_image.png image_out.png
  Usage: ./imageprocessing convolve filter.png input_image.png image_out.png
  Usage: ./imageprocessing sharpen amount radius input_image.png image_out.png
  Usage: ./imageprocessing edges input_image.png image_out.png
  Usage: ./imageprocessing grey input_image.png image_out.png
  Usage: ./imageprocessing batch commands.txt
</code></pre>
</div>
</li>
<li>
<p dir="auto">The command&nbsp;<code>./imageprocessing batch commands.txt</code>&nbsp;runs each line in the file&nbsp;<code>commands.txt</code>&nbsp;as if those were the command line arguments. For example, if&nbsp;<code>commands.txt</code>&nbsp;is a file containing:

<div class="snippet-clipboard-content notranslate position-relative overflow-auto">
<pre class="notranslate"><code>  grey balls.png balls-grey.png
  box 0 balls.png balls-box0.png
  sharpen 2 5 balls.png balls-sharpen-2-5.png
</code></pre>
</div>
<p dir="auto">then running&nbsp;<code>./imageprocessing batch commands.txt</code>&nbsp;is equivalent to manually running:

<div class="snippet-clipboard-content notranslate position-relative overflow-auto">
<pre class="notranslate"><code>  ./imageprocessing grey balls.png balls-grey.png
  ./imageprocessing box 0 balls.png balls-box0.png
  ./imageprocessing sharpen 2 5 balls.png balls-sharpen-2-5.png
</code></pre>
</div>
<p dir="auto"><strong>Note:</strong>&nbsp;The&nbsp;<code>batch</code>&nbsp;command cannot handle spaces in file names.

</li>
<li>
<p dir="auto">Add your code to&nbsp;<code>convolution.cpp</code>. You may wish to add helper functions at the top. There are some suggested signatures.

</li>
<li>
<p dir="auto">Build and run and test that it is working correctly. Qt Creator has a great debugger.

</li>
<li>
<p dir="auto">You can run the following commands on the provided example images (replace&nbsp;<code>balls</code>&nbsp;with the name of each example).

<div class="snippet-clipboard-content notranslate position-relative overflow-auto">
<pre class="notranslate"><code>  ./imageprocessing grey balls.png balls-grey.png
  ./imageprocessing box 0 balls.png balls-box0.png
  ./imageprocessing box 3 balls.png balls-box3.png
  ./imageprocessing box 25 balls.png balls-box25.png
  ./imageprocessing edges balls.png balls-edges.png
  ./imageprocessing sharpen 1 5 balls.png balls-sharpen-1-5.png
  ./imageprocessing sharpen 2 5 balls.png balls-sharpen-2-5.png
  ./imageprocessing sharpen 2 10 balls.png balls-sharpen-2-10.png
  ./imageprocessing scale 100 100 balls.png balls-scale-100.png
  ./imageprocessing scale 50 100 balls.png balls-scale-50w.png
  ./imageprocessing scale 10 100 balls.png balls-scale-10w.png
  ./imageprocessing scale 100 50 balls.png balls-scale-50h.png
  ./imageprocessing scale 100 10 balls.png balls-scale-10h.png
  ./imageprocessing scale 50 50 balls.png balls-scale-50.png
  ./imageprocessing scale 10 10 balls.png balls-scale-10.png
  ./imageprocessing scale 200 200 balls.png balls-scale-200.png
  ./imageprocessing scale 50 200 balls.png balls-scale-50w-200h.png
  ./imageprocessing scale 200 50 balls.png balls-scale-200w-50h.png
  ./imageprocessing convolve filters/identity.png balls.png balls-convolve-identity.png
  ./imageprocessing convolve filters/box3.png balls.png balls-convolve-box3.png
  ./imageprocessing convolve filters/box25.png balls.png balls-convolve-box25.png
  ./imageprocessing convolve filters/linear.png balls.png balls-convolve-linear.png
  ./imageprocessing convolve filters/quadratic.png balls.png balls-convolve-quadratic.png
  ./imageprocessing convolve filters/direction.png balls.png balls-convolve-direction.png
  ./imageprocessing convolve filters/heart.png balls.png balls-convolve-heart.png
</code></pre>
</div>
</li>
<li>
<p dir="auto">The example images are:

<ul dir="auto">
<li><code>balls.png</code></li>
<li><code>bananas.png</code></li>
<li><code>puppy.png</code></li>
<li><code>wave.png</code></li>
<li><code>wikipedia.png</code></li>
</ul>
</li>
<li>
<p dir="auto">I have provided a file&nbsp;<code>run_all.txt</code>&nbsp;containing all of the commands for all of the examples. Run it via&nbsp;<code>./imageprocessing batch run_all.txt</code>. (I have also provided the script&nbsp;<code>run_all_gen.py</code>&nbsp;I used to generate&nbsp;<code>run_all.txt</code>.)

</li>
<li>
<p dir="auto">Even better, there is now an autograder which runs all the commands and compares your output to ground truth. Find it&nbsp;<a href="https://github.com/yig/graphics101-imageprocessing-autograder">here</a>.

</li>
<li>
<p dir="auto">You are encouraged to share blooper images you create while implementing the assignment on Piazza.

</li>
<li>
<p dir="auto">Create a file named&nbsp;<code>Notes.txt</code>&nbsp;in the folder. Describe any known issues or extra features. Name people in the class who deserve a star for helping you (not by giving your their code!).

</li>
<li>
<p dir="auto">When done, zip your entire&nbsp;<code>imageprocessing</code>&nbsp;directory and your&nbsp;<code>Notes.txt</code>&nbsp;file as&nbsp;<code>imageprocessing.zip</code>. There is a target named&nbsp;<code>zip</code>&nbsp;that will do this for you (<code>cmake --build . --target zip</code>) or you can use the&nbsp;<code>cpack</code>&nbsp;command from inside your build directory. If you create the zip file manually, do not include your&nbsp;<code>build</code>&nbsp;directory. It is large and unnecessary. Do not include your output images or the&nbsp;<code>examples</code>&nbsp;directory, either. They take up a lot of space and the grader will regenerate them. Upload your solution to Blackboard before the deadline.

</li>
<li>
<p dir="auto"><strong>THIS IS AN INDIVIDUAL, NOT A GROUP ASSIGNMENT. That means all code written for this assignment should be original! Although you are permitted to consult with each other while working on this assignment, code that is substantially the same will be considered cheating.</strong>&nbsp;In your&nbsp;<code>Notes.txt</code>, please note who deserves a star (who helped you with the assignment).

</li>
</ul>
<h2 dir="auto"><a id="user-content-rubric" class="anchor" href="https://github.com/yig/graphics101-imageprocessing#rubric" aria-hidden="true"></a>Rubric:</h2>
<p dir="auto"><em>Note: This assignment is scored out of 100. There are 135 points enumerated below, providing several paths to 100. You could implement&nbsp;<code>convolve()</code>,&nbsp;<code>blur_box()</code>,&nbsp;<code>scale()</code>, and&nbsp;<code>edge_detect()</code>. Or you could skip one of them and implement&nbsp;<code>sharpen()</code>&nbsp;and one of the performance enhancements.</em>

<ol dir="auto">
<li>
<p dir="auto"><strong>(25 points)</strong>&nbsp;Convolve with an arbitrary 2D filter image. The function signature is:

<div class="snippet-clipboard-content notranslate position-relative overflow-auto">
<pre class="notranslate"><code> // Convolves the `input` image with `filter`,
 // saving the result into `output`.
 // NOTE: This function assumes that `filter` is greyscale
 // (has the same values for red, green, and blue).
 void convolve( const Image&amp; input, const Image&amp; filter, Image&amp; output
 );
</code></pre>
</div>
<p dir="auto">This requires a quadruple for loop. There is no easy way around slow O(n ¬∑ radius¬≤) running time (n is the number of input image pixels). There is a folder of interesting filter images in the handout. The&nbsp;<code>main()</code>&nbsp;function ensures that the values in the filter image are greyscale, meaning that the same numbers are stored for red, green, and blue. Because most image formats store their pixel values as 8-bit numbers, assume that the filter images are stored&nbsp;<strong>not</strong>&nbsp;normalized. Normalize them when you apply them by dividing by the sum of all pixel values. Don‚Äôt forget that the indices into filter are negated. See the tip below about&nbsp;<code>.flip().mirror()</code>.

</li>
<li>
<p dir="auto"><strong>(25 points)</strong>&nbsp;Blur with a box filter. Blurring with a box filter is one of the simplest kinds of convolution there is. It simply replaces each pixel with the unweighted average of nearby pixels. For a box, nearby pixels are those whose x or y coordinates are differ by at most radius. The function signature is:

<div class="snippet-clipboard-content notranslate position-relative overflow-auto">
<pre class="notranslate"><code> // Applies a box blur with `radius` to `input`, saving the result
 // into `output`.
 void blur_box( const Image&amp; input, int radius, Image&amp; output );
</code></pre>
</div>
<p dir="auto">A naive implementation of this takes O(n ¬∑ radius¬≤) running time (n is the number of input image pixels). You must implement it with faster running time. Because a 2D box filter is separable, you can reduce the running time to O(n ¬∑ radius) by first blurring horizontally and then blurring vertically (or vice versa).

<ol dir="auto">
<li><strong>(10 additional points)</strong>&nbsp;Because the box filter is unweighted, it is theoretically possible to achieve O(n) running time.</li>
</ol>
</li>
<li>
<p dir="auto"><strong>(15 points)</strong>&nbsp;Sharpen the image. Sharpening is the opposite of blurring. Therefore, a simple formula for a sharpened image is:&nbsp;<em>sharpen(I) = (1 + Œ±)¬∑I ‚Äì Œ±¬∑blur(I)</em>, where&nbsp;<em>Œ±</em>&nbsp;controls the amount of sharpening. You can use your box blur, and then compute the formula per-pixel. The function signature is:

<div class="snippet-clipboard-content notranslate position-relative overflow-auto">
<pre class="notranslate"><code> // Sharpens the `input` image by moving `amount` away from a blur with `radius`.
 // Saves the result into `output`.
 void sharpen( const Image&amp; input, real amount, int radius, Image&amp; output );
</code></pre>
</div>
</li>
<li>
<p dir="auto"><strong>(25 points)</strong>&nbsp;Scale the image to a new dimension. The function signature is:

<div class="snippet-clipboard-content notranslate position-relative overflow-auto">
<pre class="notranslate"><code> // Scales the `input` image to the new dimensions, saving the result
 // into `output`.
 void scale( const Image&amp; input, int new_width, int new_height, Image&amp; output );
</code></pre>
</div>
<p dir="auto">In theory, scaling reconstructs a continuous function from the input image and then resamples it at evenly spaced locations (the pixels of the output image). The reconstructed continuous function is obtained by convolving a continuous filter with our discrete input image. Note that we only need the values of the reconstructed function at output pixel locations. Therefore, you will iterate over the pixels of the output image and compute the convolution of a continuous filter with the input image. The only difference between convolving with a discrete filter (array)&nbsp;<em>b</em>&nbsp;versus a continuous filter&nbsp;<em>f</em>&nbsp;is that you will make a function call&nbsp;<em>f(x)</em>&nbsp;or&nbsp;<em>f(x,y)</em>&nbsp;to access the filter values instead of looking them up in an array&nbsp;<em>b</em>[x] or&nbsp;<em>b</em>[x,y]. The filter you will use is a triangle function:

<p dir="auto">triangle( radius,&nbsp;<em>x</em>&nbsp;) = max( 0, 1 ‚Äì |&nbsp;<em>x</em>/radius | )

<p dir="auto">You will need to normalize this on-the-fly.

In 2D, the filter is

<p dir="auto"><em>f(x,y)</em>&nbsp;= triangle( radius<sub>x</sub>,&nbsp;<em>x</em>&nbsp;) ¬∑ triangle( radius<sub>y</sub>,&nbsp;<em>y</em>&nbsp;)

<p dir="auto">By picking the right right radius for x and y, the scaling function will eliminate high frequencies that cause aliasing artifacts. The formula for the radius is:

<div class="snippet-clipboard-content notranslate position-relative overflow-auto">
<pre class="notranslate"><code> if new_size &gt; old_size: radius = 1
 else: radius = old_size/new_size
</code></pre>
</div>
<p dir="auto">where size is the width or height. Pseudocode for 1D image resizing can be found on slide 53 of&nbsp;<em>10 Signal Processing</em>&nbsp;or in the book (<em>Fundamentals of Computer Graphics</em>, Chapter 9&nbsp;<em>Signal Processing</em>).

<ol dir="auto">
<li><strong>(additional 10 points)</strong>&nbsp;The triangle filter is separable, so you can implement scaling in O(n ¬∑ radius) time by first scaling horizontally and then scaling vertically (or vice versa).</li>
</ol>
</li>
<li>
<p dir="auto"><strong>(25 points)</strong>&nbsp;Detect edges. Edge detection can be implemented in various ways. The reference implementation uses 1D convolution with the filter [ -1 0 1 ]. Convolving with the filter horizontally produces a&nbsp;<em>D<sub>x</sub></em>&nbsp;image and vertically produces a&nbsp;<em>D<sub>y</sub></em>&nbsp;image. Note that this filter cannot be normalized, since it sums to 0. Also note that this filter will produce positive and negative values; store the absolute value. The final value for a pixel of the edge detected image is sqrt(&nbsp;<em>D<sub>x</sub></em>&nbsp;¬≤ +&nbsp;<em>D<sub>y</sub></em>&nbsp;¬≤ ). The function signature is:

<div class="snippet-clipboard-content notranslate position-relative overflow-auto">
<pre class="notranslate"><code> // Performs edge detection on the `input` image.
 // Stores the result into `output`.
 void edge_detect( const Image&amp; input, Image&amp; output );
</code></pre>
</div>
</li>
</ol>
<p dir="auto">Edge detect doesn‚Äôt make sense if part of the filter is off the canvas, so set pixels along the boundary of the image to black (no edges). If you want to be fancy, you could convolve vertically along the left and right edges and vertically along the top and bottom edges, or you could virtually extend the image by repeating the closest value.

<ol dir="auto" start="6">
<li><strong>(additional ? points)</strong>&nbsp;Additional operations. Make suggestions!</li>
</ol>
<h2 dir="auto"><a id="user-content-tips" class="anchor" href="https://github.com/yig/graphics101-imageprocessing#tips" aria-hidden="true"></a>Tips</h2>
<ul dir="auto">
<li>
<p dir="auto">All the code you write will go into&nbsp;<code>convolution.cpp</code>.

</li>
<li>
<p dir="auto">Convolution operates on the red, green, and blue channels of the image independently. Ignore alpha. (Even preserving alpha would produce the wrong result.)

</li>
<li>
<p dir="auto">You will want almost all of the filters you will implement to be normalized, meaning that their values sum to 1. Only edge detection makes use of filters which sum to 0. Don‚Äôt normalize edge detection filters. The&nbsp;<code>convolve()</code>&nbsp;function takes in unnormalized filters; you can normalize on-the-fly.

</li>
<li>
<p dir="auto">It is easy to normalize on-the-fly by keeping track of the denominator.

</li>
<li>
<p dir="auto">When convolving near the edges of an image, only apply the portion of the filter that lies in the image (ignore out-of-bounds pixels). When you do this, you will be ignoring part of the filter. Therefore, the part of the filter that you do use will no longer sum to one. You will need to renormalize by dividing by the sum of non-ignored filter values.

</li>
<li>
<p dir="auto">Don‚Äôt store partial sums in a&nbsp;<code>ColorRGBA8</code>, which have only 8-bit precision for each channel. If your partial sums are real numbers, you would lose a lot of precision if you round after each addition. If you are normalizing on-the-fly, the partial sums may overflow, because the sum of 8-bit numbers often won‚Äôt fit into another 8-bit number. When storing the results back into a&nbsp;<code>ColorRGBA8</code>, make sure values are in the range [0,255]. You can use&nbsp;<code>min()</code>&nbsp;and&nbsp;<code>max()</code>&nbsp;or the provided&nbsp;<code>clamp()</code>&nbsp;helper function.

</li>
<li>
<p dir="auto">You can‚Äôt perform convolution in-place, because you will be overwriting values that you still need to read. If a function makes use of separable convolution, don‚Äôt forget to create a temporary intermediate image or array (<code>std::vector&lt;int&gt;</code>) as necessary.

</li>
<li>
<p dir="auto">You can halve the amount of code you need to write for separable filters by iterating with pointers to pixel data. See the discussion of&nbsp;<code>image.scanline()</code>&nbsp;below. For non-separable functions, working with pointers to pixel data will not reduce the amount of code you write (though the code will run faster).

</li>
<li>
<p dir="auto">Convolution, correctly defined, says that you iterate over the filter with flipped (negated) coordinates. This only matters for unsymmetrical filters. The only ones you will encounter are&nbsp;<code>heart.png</code>&nbsp;and&nbsp;<code>direction.png</code>. You should use&nbsp;<code>filter.flip().mirror()</code>&nbsp;instead of&nbsp;<code>filter</code>&nbsp;to get the correct results (unless you flip your filter coordinates).

</li>
<li>
<p dir="auto">You can compare your output in a few ways:

<ul dir="auto">
<li>
<p dir="auto">With the&nbsp;<a href="https://github.com/yig/graphics101-imageprocessing-autograder">autograder</a>.

</li>
<li>
<p dir="auto">Open both images in a viewer which lets you flip back and forth in-place with, for example, the right and left arrow keys. You could, for example, open them in browser tabs and switch tabs back-and-forth. Rapidly switching back and forth in-place is a good technique to visually understand the differences.

</li>
<li>
<p dir="auto">With the built-in function&nbsp;<code>difference()</code>, accessible from the command line via:

<div class="snippet-clipboard-content notranslate position-relative overflow-auto">
<pre class="notranslate"><code>  ./imageprocessing difference input_image1.png input_image2.png image_out.png
</code></pre>
</div>
</li>
<li>
<p dir="auto">With the Python script provided in the&nbsp;<code>examples</code>&nbsp;directory:

<div class="snippet-clipboard-content notranslate position-relative overflow-auto">
<pre class="notranslate"><code>  python imgdiff.py input_image1.png input_image2.png image_out.png
</code></pre>
</div>
</li>
<li>
<p dir="auto">Do not use a program which returns true or false based on whether all the bits match. Slightly different implementations can round to slightly different answers, which is fine. Our spec is not bit-exact (and arguably should not be).

</li>
</ul>
</li>
</ul>
<h2 dir="auto"><a id="user-content-framework-functions-you-need-for-this-assignment" class="anchor" href="https://github.com/yig/graphics101-imageprocessing#framework-functions-you-need-for-this-assignment" aria-hidden="true"></a>Framework functions you need for this assignment</h2>
<p dir="auto"><strong>Image:</strong>

<ul dir="auto">
<li>
<p dir="auto"><code>image.pixel(x,y)</code>&nbsp;returns the&nbsp;<code>ColorRGBA8</code>&nbsp;color for pixel x,y of a&nbsp;<code>Image image</code>.

</li>
<li>
<p dir="auto"><code>image.pixel(x,y) = c</code>&nbsp;sets the pixel to a&nbsp;<code>ColorRGBA8</code>&nbsp;color&nbsp;<code>c</code>. The top left pixel is (0,0), not the bottom left pixel.

</li>
<li>
<p dir="auto"><code>image.width()</code>&nbsp;and&nbsp;<code>image.height()</code>&nbsp;return the width and height of the image.

</li>
<li>
<p dir="auto"><code>image.scanline(y)</code>&nbsp;returns a pointer to the array of&nbsp;<code>ColorRGBA8</code>&nbsp;pixel data for row y. That pointer points to the pixel (0,y). If you have a pointer to a pixel&nbsp;<code>ColorRGBA8* pix</code>, the next pixel in the row is&nbsp;<code>pix+1</code>&nbsp;and the next pixel in the column is&nbsp;<code>pix+image.width()</code>. Therefore, the pointer to the first pixel in column x is&nbsp;<code>image.scanline(0)+x</code>. By keeping track of the&nbsp;<em>stride</em>&nbsp;between pixels, you can write general functions that iterate over either rows or columns. Such a function would take a pointer to the first pixel, the stride between pixels, and the number of pixels. This can substantially reduce the amount of code you need to write when you only need to iterate over an image‚Äôs rows or columns, as opposed to iterating over a square region. The code will also run faster. For an example of how to use these methods, see the&nbsp;<code>greyscale()</code>&nbsp;function.

</li>
<li>
<p dir="auto"><code>Image( width, height )</code>&nbsp;creates a blank image full of undefined&nbsp;<code>ColorRGBA8</code>&nbsp;pixels.&nbsp;<code>Image( width, height, color )</code>&nbsp;creates an image filled with the given&nbsp;<code>ColorRGBA8 color</code>. Set pixel values via&nbsp;<code>.pixel()</code>&nbsp;or&nbsp;<code>.fill()</code>.

</li>
<li>
<p dir="auto"><code>Image(image).flip().mirror()</code>&nbsp;returns a copy of&nbsp;<code>image</code>&nbsp;mirrored horizontally and vertically.

</li>
</ul>
<p dir="auto"><code>sqrt(x)</code>,&nbsp;<code>std::min(a,b)</code>,&nbsp;<code>std::max(a,b)</code>,&nbsp;<code>lround(x)</code>,&nbsp;<code>floor(x)</code>,&nbsp;<code>ceil(x)</code>. These are part of C‚Äôs&nbsp;<code>math.h</code>&nbsp;(in C++ included as&nbsp;<code>&lt;cmath&gt;</code>) and C++‚Äôs&nbsp;<code>&lt;algorithm&gt;</code>. You will find them useful. Note that&nbsp;<code>std::min</code>&nbsp;and&nbsp;<code>std::max</code>&nbsp;require both parameters to have the exact same type. If not, you will get a very long compiler error since they are generic functions written using C++ templates.

<p dir="auto"><strong>ColorRGBA8</strong>&nbsp;To get the red, green, blue, and alpha components of a&nbsp;<code>ColorRGBA8</code>&nbsp;color&nbsp;<code>c</code>&nbsp;as 8-bit values, use&nbsp;<code>c.r</code>,&nbsp;<code>c.g</code>,&nbsp;<code>c.b</code>, and&nbsp;<code>c.a</code>. In this assignment, we are ignoring alpha. To create an RGB&nbsp;<code>ColorRGBA8</code>&nbsp;color, use&nbsp;<code>ColorRGBA8( red, green, blue )</code>&nbsp;with 8-bit parameters. Each of the parameters should be an integer number in the range [0,255], inclusive. Note that&nbsp;<code>ColorRGBA8</code>&nbsp;is a 4-byte struct; some packages instead use a&nbsp;<code>typedef</code>&nbsp;for an&nbsp;<code>unsigned int</code>&nbsp;and then perform bitwise manipulation to store the appropriate bytes.
